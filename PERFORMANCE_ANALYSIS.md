# An√°lise de Performance: Batch Inserts em PostgreSQL

## üéØ Problema Identificado

**Situa√ß√£o:** Inser√ß√£o paralela com batch √© **MAIS LENTA** que inser√ß√£o sequencial para 10.000 registros.

**Por qu√™?** Paralelismo adiciona overhead que supera os benef√≠cios em datasets pequenos.

---

## üìä Resultados Esperados (10k registros)

| M√©todo | Tempo Estimado | Registros/s | Explica√ß√£o |
|--------|---------------|-------------|------------|
| **Otimizado (Transa√ß√£o √∫nica)** | ~2-3s | ~3500-5000 | ‚úÖ MELHOR op√ß√£o |
| Standard (executemany) | ~5-7s | ~1500-2000 | ‚ö†Ô∏è M√∫ltiplas queries |
| Paralelo com Pool | ~4-6s | ~1800-2500 | ‚ö†Ô∏è Overhead para dataset pequeno |
| Paralelo sem Pool | ~8-12s | ~800-1200 | ‚ùå PIOR - cria conex√µes novas |

---

## üîç An√°lise Detalhada dos Problemas

### 1. **Overhead de Conex√µes (`batch_process_rows`)**

```python
# PROBLEMA: Cada batch abre uma NOVA conex√£o
def insert_batch(self, table_name, data_batch):
    with psycopg.connect(self.conn_str) as conn:  # ‚ùå Nova conex√£o!
        with conn.cursor() as cur:
            cur.executemany(query, values)
        conn.commit()  # ‚ùå Commit separado!
```

**Impacto com 10k registros:**
- 10 batches √ó 50-100ms de handshake = **500-1000ms de overhead**
- 10 transa√ß√µes √ó commit overhead = **200-500ms adicional**
- **Total: ~700-1500ms perdidos s√≥ em conex√µes!**

---

### 2. **Lock Contention (Conten√ß√£o de Bloqueios)**

Quando m√∫ltiplas threads tentam inserir na mesma tabela:

```sql
Thread 1: INSERT INTO artigos ...  [Aguarda lock]
Thread 2: INSERT INTO artigos ...  [Aguarda lock]
Thread 3: INSERT INTO artigos ...  [Aguarda lock]
```

PostgreSQL **serializa** as opera√ß√µes, negando o benef√≠cio do paralelismo.

---

### 3. **Overhead de Threads para Dataset Pequeno**

Com 10.000 registros e batch_size=1000:
- **Apenas 10 batches** para processar
- Overhead de ThreadPoolExecutor: ~100-200ms
- Sincroniza√ß√£o entre threads: ~50-100ms
- **Resultado:** Gastamos mais tempo gerenciando threads que executando SQL

---

### 4. **M√∫ltiplos Commits vs Transa√ß√£o √önica**

```python
# ‚ùå LENTO: 10 commits separados
for batch in batches:
    insert_batch(batch)
    conn.commit()  # WAL flush + fsync √ó 10 vezes

# ‚úÖ R√ÅPIDO: 1 commit √∫nico
with conn:
    for batch in batches:
        insert_batch(batch)
    conn.commit()  # WAL flush + fsync √ó 1 vez
```

**Custo de cada commit:**
- Write-Ahead Log (WAL) flush: ~20-50ms
- fsync ao disco: ~10-30ms
- **10 commits = 300-800ms de overhead!**

---

## ‚úÖ Solu√ß√£o Implementada

### M√©todo Otimizado: `insert_optimized_single_transaction()`

```python
def insert_optimized_single_transaction(self, table_name, data_model_list):
    """
    ‚úÖ Uma conex√£o
    ‚úÖ Uma transa√ß√£o
    ‚úÖ execute_values (batch real)
    ‚úÖ Sem overhead de paralelismo
    """
    with psycopg.connect(self.conn_str) as conn:
        with conn.cursor() as cur:
            execute_values(cur, query, values, page_size=1000)
        conn.commit()  # Apenas 1 commit
```

**Vantagens:**
1. **execute_values:** Converte m√∫ltiplos inserts em UMA query SQL otimizada
2. **Transa√ß√£o √∫nica:** Apenas 1 commit/fsync
3. **Uma conex√£o:** Zero overhead de handshake
4. **page_size=1000:** Batch interno eficiente

---

## üéì Para sua Monografia/Tese

### Conceitos Importantes a Discutir:

#### 1. **Trade-off Paralelismo vs Overhead**
```
Benef√≠cio do Paralelismo > Overhead?
    ‚úÖ Sim ‚Üí Use paralelo
    ‚ùå N√£o ‚Üí Use sequencial otimizado

Overhead inclui:
- Cria√ß√£o/gerenciamento de threads
- Sincroniza√ß√£o
- Conex√µes ao banco
- Lock contention
```

#### 2. **Quando Usar Cada M√©todo**

| Dataset | M√©todo Recomendado | Justificativa |
|---------|-------------------|---------------|
| < 10k | Transa√ß√£o √∫nica | Overhead > benef√≠cio |
| 10k - 100k | Transa√ß√£o √∫nica | Ainda eficiente |
| 100k - 500k | Considerar paralelo | Come√ßar a valer a pena |
| > 500k | Paralelo com pool | Benef√≠cio > overhead |

#### 3. **Otimiza√ß√µes PostgreSQL**

```sql
-- Para inserts massivos, configure:
SET synchronous_commit = OFF;  -- Durante carga inicial
SET maintenance_work_mem = '256MB';
SET checkpoint_completion_target = 0.9;
```

#### 4. **Benchmarks Cient√≠ficos**

Estrutura de teste para sua tese:
```python
# 1. Controlar vari√°veis
# 2. M√∫ltiplas execu√ß√µes (n=5 ou mais)
# 3. Calcular m√©dia e desvio padr√£o
# 4. Variar tamanho do dataset (10k, 50k, 100k, 500k)
# 5. Documentar configura√ß√£o (CPU, RAM, PostgreSQL version, disco)
```

---

## üöÄ Como Executar os Testes

### 1. Teste R√°pido (m√©todo otimizado)
```bash
cd /Users/raphaelportela/monografia_2025/mono_2025
python fetch_db.py
```

### 2. Teste Completo de Performance
```bash
python test_insert_performance.py
```

Este script vai:
- ‚úÖ Testar todos os 4 m√©todos
- ‚úÖ Limpar tabela entre testes
- ‚úÖ Gerar relat√≥rio comparativo
- ‚úÖ Calcular m√©tricas (tempo, registros/s, speedup)

---

## üìà Gr√°ficos Recomendados para a Tese

### 1. **Performance vs Tamanho do Dataset**
```
Eixo X: N√∫mero de registros (10k, 50k, 100k, 500k, 1M)
Eixo Y: Tempo (segundos)
Linhas: Cada m√©todo
```

### 2. **Throughput (Registros/segundo)**
```
Eixo X: N√∫mero de threads (1, 2, 3, 4, 5, 6)
Eixo Y: Registros/segundo
Dataset: Fixo (ex: 100k registros)
```

### 3. **Overhead Analysis**
```
Gr√°fico de pizza:
- Tempo de SQL real
- Overhead de conex√£o
- Overhead de threads
- Overhead de commits
```

---

## üí° Conclus√µes Chave

1. **Paralelismo n√£o √© sempre melhor**
   - Para 10k registros: Sequencial otimizado √© ~2-3x mais r√°pido

2. **Gargalos al√©m do SQL**
   - Conex√µes: 50-100ms cada
   - Commits: 30-80ms cada
   - Threads: 10-20ms de overhead por lote

3. **execute_values √© poderoso**
   - Converte N inserts em 1 query
   - Reduz round-trips ao banco
   - 2-5x mais r√°pido que executemany

4. **ConnectionPool vale a pena apenas para:**
   - M√∫ltiplas requisi√ß√µes concorrentes (ex: API)
   - Datasets muito grandes (> 500k)
   - Aplica√ß√µes long-running

5. **Benchmarking √© essencial**
   - Nunca assume que "paralelo = r√°pido"
   - Sempre teste com dados reais
   - Considere o contexto (hardware, rede, DB config)

---

## üìö Refer√™ncias T√©cnicas

- [psycopg3 Fast Execution](https://www.psycopg.org/psycopg3/docs/advanced/adapt.html#example-return-composite-types)
- [PostgreSQL COPY vs INSERT](https://www.postgresql.org/docs/current/populate.html)
- [Connection Pooling Best Practices](https://wiki.postgresql.org/wiki/Number_Of_Database_Connections)
- [Transaction Performance](https://www.postgresql.org/docs/current/populate.html#POPULATE-TRANSACTIONS)

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ Execute `test_insert_performance.py` para dados concretos
2. ‚úÖ Teste com diferentes tamanhos (10k, 50k, 100k)
3. ‚úÖ Documente configura√ß√£o do sistema (CPU, RAM, PostgreSQL)
4. ‚úÖ Gere gr√°ficos para a tese
5. ‚úÖ Considere testar COPY FROM stdin para compara√ß√£o

---

**Autor:** An√°lise de Performance PostgreSQL - ETL com psycopg3  
**Data:** Outubro 2025  
**Contexto:** Monografia sobre otimiza√ß√£o de pipelines ETL

