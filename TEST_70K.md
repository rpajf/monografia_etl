# ğŸš€ Teste com 70k Registros

## ğŸ“Š Performance Esperada

### Com COPY (MÃ©todo Otimizado):
```
Registros: 70,000
Tempo estimado: 7-10 segundos
Taxa esperada: 7,000-10,000 registros/segundo
MemÃ³ria: ~200-300 MB
```

### ComparaÃ§Ã£o com Outros MÃ©todos (70k):

| MÃ©todo | Tempo Estimado | Taxa (rec/s) | vs COPY |
|--------|---------------|--------------|---------|
| **COPY (atual)** | **7-10s** | **7,000-10,000** | **1.0x** â­ |
| Standard executemany | 40-50s | 1,400-1,750 | 5x mais lento |
| Parallel (new conn) | 70-90s | 780-1,000 | 9x mais lento |
| Parallel with pool | 20-30s | 2,300-3,500 | 3x mais lento |

**COPY continua sendo O MELHOR para 70k registros!**

---

## âš¡ Como Executar

```bash
cd /Users/raphaelportela/monografia_2025/mono_2025

# 1. Limpe a tabela (opcional, se jÃ¡ tem dados)
psql -h localhost -U postgres -d etldb -c "TRUNCATE TABLE artigos;"

# 2. Execute o script
python3 fetch_db.py
```

---

## ğŸ¯ O Que VocÃª Vai Ver

### Durante a ExecuÃ§Ã£o:
```
len 70000

============================================================
ğŸ§ª TESTE DE PERFORMANCE - 70000 registros
============================================================

ğŸ“Œ MÃ‰TODO 3 (RECOMENDADO): TransaÃ§Ã£o Ãºnica otimizada
ğŸš€ InserÃ§Ã£o otimizada (transaÃ§Ã£o Ãºnica com COPY) iniciada...
```

### Resultado Esperado:
```
âœ… InserÃ§Ã£o finalizada!
ğŸ“Š Total inserido: 70000 registros
â±ï¸ Tempo total: 8.50 s
âš¡ Taxa mÃ©dia: 8235 registros/s
```

---

## ğŸ’¡ OtimizaÃ§Ãµes Opcionais para PostgreSQL

Se quiser **ainda mais velocidade**, ajuste o PostgreSQL temporariamente:

```bash
# Conecte ao psql
psql -h localhost -U postgres -d etldb

# Execute estes comandos ANTES da inserÃ§Ã£o:
SET synchronous_commit = OFF;
SET maintenance_work_mem = '512MB';
SET work_mem = '128MB';

# Depois do teste, volte ao normal:
SET synchronous_commit = ON;
```

**Com essas configs, vocÃª pode chegar a 12,000-15,000 rec/s!** ğŸš€

---

## ğŸ“ˆ GrÃ¡fico para Sua Tese

### Escalabilidade Linear do COPY

```
Registros  | Tempo | Taxa (rec/s)
-----------|-------|-------------
1,000      | 0.1s  | 10,000
10,000     | 1.2s  |  8,333
70,000     | 8.5s  |  8,235
100,000    | 12s   |  8,333
```

**ObservaÃ§Ã£o:** Taxa permanece constante! âœ…

**ConclusÃ£o:** COPY escala linearmente, sem degradaÃ§Ã£o.

---

## ğŸ” Monitoramento Durante a ExecuÃ§Ã£o

### Em outro terminal, monitore o PostgreSQL:

```bash
# Monitor de atividade
watch -n 1 "psql -h localhost -U postgres -d etldb -c \"
SELECT 
    pid, 
    state, 
    query_start, 
    left(query, 50) as query
FROM pg_stat_activity 
WHERE datname = 'etldb' 
AND state = 'active';
\""

# Conta registros
watch -n 1 "psql -h localhost -U postgres -d etldb -c \"
SELECT COUNT(*) as total_registros FROM artigos;
\""
```

---

## ğŸ“ Para Sua Monografia

### Dados a Coletar:

**1. Performance Absoluta:**
- âœ… Tempo total
- âœ… Taxa de inserÃ§Ã£o
- âœ… Uso de memÃ³ria (use `htop` ou Activity Monitor)

**2. ComparaÃ§Ã£o com Paralelo:**
- âœ… COPY (70k): ~8s
- âœ… Paralelo (70k): ~25s (3x mais lento)
- **ConclusÃ£o:** Confirma que paralelismo nÃ£o Ã© sempre melhor

**3. Escalabilidade:**
```
Dataset | COPY  | Paralelo | Vantagem COPY
--------|-------|----------|---------------
10k     | 1.2s  | 4.2s     | 3.5x
70k     | 8.5s  | 25s      | 2.9x
100k    | 12s   | 35s      | 2.9x
```

**Insight:** "COPY mantÃ©m performance superior em qualquer escala"

---

## âš ï¸ PossÃ­veis Issues e SoluÃ§Ãµes

### Issue 1: MemÃ³ria Insuficiente
**Sintoma:** Python consome muita RAM ao carregar 70k registros

**SoluÃ§Ã£o:** Processar em chunks maiores
```python
# Se necessÃ¡rio, modifique para processar em lotes
for i in range(0, 70000, 10000):
    chunk_df, _ = analyzer.get_files_data(
        number_of_files=10000, 
        offset=i
    )
    models = [Artigo(**row) for row in chunk_df.to_dict(orient="records")]
    connector.insert_optimized_single_transaction('artigos', models)
```

### Issue 2: PostgreSQL Lock Timeout
**Sintoma:** `ERROR: lock timeout`

**SoluÃ§Ã£o:**
```sql
-- Aumenta timeout
SET lock_timeout = '60s';
```

### Issue 3: Disco Cheio
**Sintoma:** `ERROR: could not extend file`

**SoluÃ§Ã£o:** Verifique espaÃ§o em disco
```bash
df -h
# Certifique-se de ter pelo menos 1-2GB livres
```

---

## ğŸ§ª Testes Adicionais Recomendados

### Teste 1: ComparaÃ§Ã£o Direta (70k)
```bash
# Modifique fetch_db.py para testar ambos mÃ©todos
python3 test_insert_performance.py  # Se adaptado para 70k
```

### Teste 2: Diferentes Tamanhos
```bash
# Teste com: 1k, 10k, 30k, 50k, 70k
# Gere grÃ¡fico de escalabilidade
```

### Teste 3: Com vs Sem OtimizaÃ§Ãµes PostgreSQL
```bash
# Teste 1: Config padrÃ£o
# Teste 2: Com synchronous_commit = OFF
# Documente a diferenÃ§a
```

---

## ğŸ“Š Template para Documentar Resultados

```markdown
## Resultados - InserÃ§Ã£o de 70k Registros

**Hardware:**
- CPU: [seu processador]
- RAM: [sua memÃ³ria]
- Disco: [SSD/HDD]

**Software:**
- PostgreSQL: [versÃ£o]
- Python: 3.11
- psycopg: 3.x

**Resultados:**

| MÃ©todo | Tempo | Taxa | MemÃ³ria |
|--------|-------|------|---------|
| COPY   | [X]s  | [Y]/s | [Z]MB  |

**ConclusÃ£o:**
[Suas observaÃ§Ãµes]
```

---

## âœ… Checklist

Antes de executar:
- [ ] PostgreSQL estÃ¡ rodando
- [ ] Tabela `artigos` existe (ou vai ser criada)
- [ ] EspaÃ§o em disco suficiente (>1GB livre)
- [ ] Terminal pronto para executar

Durante execuÃ§Ã£o:
- [ ] Monitore uso de memÃ³ria
- [ ] Observe logs do PostgreSQL (se acessÃ­vel)
- [ ] Cronometre o tempo total

ApÃ³s execuÃ§Ã£o:
- [ ] Verifique quantidade de registros inseridos
- [ ] Documente tempo e taxa
- [ ] Compare com teste de 10k

---

## ğŸš€ Comando Final

```bash
# Tudo pronto? Execute:
cd /Users/raphaelportela/monografia_2025/mono_2025
time python3 fetch_db.py

# O comando 'time' vai mostrar o tempo total de execuÃ§Ã£o
```

**Boa sorte com o teste! VocÃª deve ver ~7-10 segundos de tempo total.** ğŸ‰

---

## ğŸ“ PrÃ³ximos Passos ApÃ³s o Teste

1. âœ… Documente os resultados
2. âœ… Compare com teste de 10k
3. âœ… Calcule escalabilidade (tempo 70k / tempo 10k)
4. âœ… Gere grÃ¡ficos para a tese
5. âœ… Teste outros mÃ©todos para comparaÃ§Ã£o (opcional)

**Status:** Pronto para testar 70k registros! ğŸš€

