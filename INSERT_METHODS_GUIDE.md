# Guia RÃ¡pido: Escolher MÃ©todo de InserÃ§Ã£o PostgreSQL

## ğŸ¯ Ãrvore de DecisÃ£o

```
Quantos registros vocÃª tem?
â”‚
â”œâ”€ < 100k registros
â”‚  â””â”€ âœ… Use: insert_optimized_single_transaction()
â”‚     Por quÃª? Overhead de paralelismo > benefÃ­cio
â”‚
â”œâ”€ 100k - 500k registros
â”‚  â”œâ”€ Ã‰ carga Ãºnica (batch job)?
â”‚  â”‚  â””â”€ âœ… Use: insert_optimized_single_transaction()
â”‚  â”‚
â”‚  â””â”€ Ã‰ API com mÃºltiplas requisiÃ§Ãµes concorrentes?
â”‚     â””â”€ âœ… Use: batch_process_with_pool()
â”‚        ConfiguraÃ§Ã£o: batch_size=10000, max_workers=3-4
â”‚
â””â”€ > 500k registros
   â””â”€ âœ… Use: batch_process_with_pool()
      ConfiguraÃ§Ã£o: batch_size=20000, max_workers=4-6
      OU considere PostgreSQL COPY FROM stdin
```

---

## ğŸ“‹ ComparaÃ§Ã£o RÃ¡pida

| MÃ©todo | Melhor Para | Vantagens | Desvantagens |
|--------|-------------|-----------|--------------|
| **insert_optimized_single_transaction()** | < 100k registros | âš¡ Mais rÃ¡pido<br>ğŸ”§ Simples<br>ğŸ’¾ Baixo overhead | âŒ NÃ£o escala para milhÃµes |
| **batch_process_with_pool()** | > 500k registros<br>APIs concorrentes | ğŸ”„ Reutiliza conexÃµes<br>âš¡ Paralelo real | âš™ï¸ Requer tuning<br>ğŸŒ Lento para poucos dados |
| **batch_process_rows()** | âŒ NUNCA | Nenhuma | âŒ Cria conexÃµes novas<br>âŒ Muito lento |
| **insert_into_table_typed()** | Testes/Debug | ğŸ”§ Simples | ğŸŒ Lento (executemany) |

---

## ğŸš€ Exemplos de Uso

### Exemplo 1: Dataset Pequeno (seu caso - 10k registros)

```python
from etl_psycopg3 import DatabaseConnector
from schemas import Artigo

# Carrega dados
models = [Artigo(**row) for row in df.to_dict(orient="records")]

# InserÃ§Ã£o otimizada
connector = DatabaseConnector()
connector.insert_optimized_single_transaction(
    table_name="artigos",
    data_model_list=models
)
```

**Resultado esperado:** ~2-3 segundos para 10k registros

---

### Exemplo 2: Dataset Grande (> 500k registros)

```python
connector = DatabaseConnector()
connector.batch_process_with_pool(
    table_name="artigos",
    data_model_list=models,
    batch_size=20000,    # Lotes grandes
    max_workers=4        # 4 threads paralelas
)
```

**Resultado esperado:** ~15-20 segundos para 500k registros

---

### Exemplo 3: API com RequisiÃ§Ãµes Concorrentes

```python
# Cria pool uma vez no startup da aplicaÃ§Ã£o
connector = DatabaseConnector()  # Pool criado no __init__

# Em cada endpoint, use:
@app.post("/artigos")
def create_artigos(artigos: list[Artigo]):
    connector.batch_process_with_pool(
        table_name="artigos",
        data_model_list=artigos,
        batch_size=5000,
        max_workers=3
    )
```

---

## âš™ï¸ ConfiguraÃ§Ãµes Recomendadas

### Para dataset pequeno (< 100k)
```python
connector.insert_optimized_single_transaction(
    table_name="tabela",
    data_model_list=models
)
# Sem configuraÃ§Ã£o necessÃ¡ria - jÃ¡ otimizado!
```

### Para dataset mÃ©dio (100k-500k)
```python
connector.batch_process_with_pool(
    table_name="tabela",
    data_model_list=models,
    batch_size=10000,    # Lotes mÃ©dios
    max_workers=3        # Poucos workers
)
```

### Para dataset grande (> 500k)
```python
connector.batch_process_with_pool(
    table_name="tabela",
    data_model_list=models,
    batch_size=20000,    # Lotes grandes
    max_workers=6        # Mais workers
)
```

---

## ğŸ”§ Tuning AvanÃ§ado

### 1. Batch Size (tamanho do lote)

| Registros | batch_size recomendado | RazÃ£o |
|-----------|----------------------|-------|
| < 10k | N/A (use transaÃ§Ã£o Ãºnica) | Overhead > benefÃ­cio |
| 10k-50k | 5000 | Balance overhead/parallelismo |
| 50k-200k | 10000 | Lotes mÃ©dios eficientes |
| 200k-1M | 20000 | Lotes grandes, menos overhead |
| > 1M | 50000 | Maximiza throughput |

### 2. Max Workers (nÃºmero de threads)

```python
# FÃ³rmula: min(num_cpu_cores, num_batches / 2)

import os
num_cores = os.cpu_count()
num_batches = len(models) / batch_size
optimal_workers = min(num_cores, num_batches // 2, 6)
```

**Por quÃª limitar?**
- Mais threads = mais lock contention no PostgreSQL
- Sweet spot: 3-6 workers para maioria dos casos

### 3. PostgreSQL Tuning

Para cargas massivas, otimize PostgreSQL:

```sql
-- Antes da carga
SET synchronous_commit = OFF;
SET maintenance_work_mem = '256MB';
SET work_mem = '64MB';
SET checkpoint_completion_target = 0.9;

-- ApÃ³s a carga
SET synchronous_commit = ON;
```

---

## âš ï¸ Armadilhas Comuns

### âŒ Armadilha 1: "Mais threads = mais rÃ¡pido"
```python
# ERRADO
connector.batch_process_with_pool(
    table_name="artigos",
    data_model_list=models,  # 10k registros
    batch_size=1000,
    max_workers=20  # âŒ Muito overhead!
)
```

**CorreÃ§Ã£o:** Use `insert_optimized_single_transaction()` para < 100k

---

### âŒ Armadilha 2: "Batch size pequeno Ã© mais seguro"
```python
# ERRADO
connector.batch_process_with_pool(
    table_name="artigos",
    data_model_list=models,  # 500k registros
    batch_size=100,  # âŒ Muito pequeno!
    max_workers=5
)
```

**Problema:** 5000 batches = overhead enorme

**CorreÃ§Ã£o:** Use batch_size=20000 (25 batches)

---

### âŒ Armadilha 3: "ConnectionPool sempre Ã© melhor"
```python
# DESNECESSÃRIO
connector.batch_process_with_pool(
    table_name="artigos",
    data_model_list=models,  # 5k registros
    batch_size=1000,
    max_workers=3
)
```

**Problema:** Overhead de pool + threads para poucos dados

**CorreÃ§Ã£o:** Use `insert_optimized_single_transaction()`

---

## ğŸ“Š Benchmark do Seu Sistema

Execute este script para descobrir os limites do SEU sistema:

```python
# test_your_limits.py
from test_insert_performance import test_all_methods

# Teste com diferentes tamanhos
for size in [1000, 5000, 10000, 50000, 100000]:
    print(f"\n{'='*60}")
    print(f"Testing with {size} records")
    print(f"{'='*60}")
    test_all_methods(num_records=size)
```

---

## ğŸ“ Para sua Monografia

### SeÃ§Ã£o: "AnÃ¡lise de Performance"

1. **IntroduÃ§Ã£o ao Problema**
   - Paralelismo nem sempre Ã© melhor
   - Overhead vs benefÃ­cio

2. **Metodologia**
   - 4 mÃ©todos testados
   - ConfiguraÃ§Ã£o do ambiente
   - Dataset utilizado (COVID-19, Kaggle)

3. **Resultados**
   - GrÃ¡ficos comparativos
   - Tabelas de performance
   - AnÃ¡lise de overhead

4. **DiscussÃ£o**
   - Por que paralelo Ã© mais lento em datasets pequenos
   - Trade-offs de cada abordagem
   - RecomendaÃ§Ãµes prÃ¡ticas

5. **ConclusÃ£o**
   - ImportÃ¢ncia de benchmarking
   - Guia de decisÃ£o criado
   - LiÃ§Ãµes aprendidas

---

## ğŸ”— Arquivos Relacionados

- `PERFORMANCE_ANALYSIS.md` - AnÃ¡lise detalhada tÃ©cnica
- `test_insert_performance.py` - Script de benchmark completo
- `etl_psycopg3.py` - ImplementaÃ§Ã£o dos mÃ©todos
- `fetch_db.py` - Pipeline ETL completo

---

**Ãšltima atualizaÃ§Ã£o:** Outubro 2025  
**Status:** âœ… Pronto para uso em produÃ§Ã£o e documentaÃ§Ã£o acadÃªmica

